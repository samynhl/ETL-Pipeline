{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning models applied to the data collected from the twitter api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim --upgrade\n",
    "# !pip install keras --upgrade\n",
    "# !pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.3.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.6/769.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.3 nltk-3.8.1 regex-2023.3.23 tqdm-4.65.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"text\",\"favorite_count\",\t\"date_creation\",\"retweet_count\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>date_creation</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ispace_inc Stream on Twitter too!</td>\n",
       "      <td>3014</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@zerohedge So bizarre that people and companie...</td>\n",
       "      <td>7200</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@stillgray Really? 🤔</td>\n",
       "      <td>11125</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_CryMiaRiver @krassenstein @ZubyMusic I repea...</td>\n",
       "      <td>7635</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@krassenstein @ZubyMusic Please correct if wro...</td>\n",
       "      <td>2240</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>@unusual_whales Nice. Just me here @elonmusk t...</td>\n",
       "      <td>10341</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>@ErcXspace @SpaceX Gravity, gravity, \\ntime to...</td>\n",
       "      <td>5793</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>Or maybe just X https://t.co/5nCtYbrPfN</td>\n",
       "      <td>61164</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>6187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>@SawyerMerritt @SpaceX @Tesla Yay!</td>\n",
       "      <td>5042</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>@all_in_tok @DavidSacks @theallinpod Wow</td>\n",
       "      <td>1741</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  favorite_count   \n",
       "0                    @ispace_inc Stream on Twitter too!            3014  \\\n",
       "1     @zerohedge So bizarre that people and companie...            7200   \n",
       "2                                  @stillgray Really? 🤔           11125   \n",
       "3     @_CryMiaRiver @krassenstein @ZubyMusic I repea...            7635   \n",
       "4     @krassenstein @ZubyMusic Please correct if wro...            2240   \n",
       "...                                                 ...             ...   \n",
       "1171  @unusual_whales Nice. Just me here @elonmusk t...           10341   \n",
       "1172  @ErcXspace @SpaceX Gravity, gravity, \\ntime to...            5793   \n",
       "1173            Or maybe just X https://t.co/5nCtYbrPfN           61164   \n",
       "1174                 @SawyerMerritt @SpaceX @Tesla Yay!            5042   \n",
       "1175           @all_in_tok @DavidSacks @theallinpod Wow            1741   \n",
       "\n",
       "     date_creation  retweet_count  \n",
       "0       2023-04-25            285  \n",
       "1       2023-04-25            636  \n",
       "2       2023-04-25            977  \n",
       "3       2023-04-25           1244  \n",
       "4       2023-04-25            108  \n",
       "...            ...            ...  \n",
       "1171    2023-04-25            484  \n",
       "1172    2023-04-24            375  \n",
       "1173    2023-04-24           6187  \n",
       "1174    2023-04-24            237  \n",
       "1175    2023-04-24            109  \n",
       "\n",
       "[1176 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('./data/TWEET_INFO_2023-04-26.csv', header=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1176\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>date_creation</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ispace_inc Stream on Twitter too!</td>\n",
       "      <td>3014</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@zerohedge So bizarre that people and companie...</td>\n",
       "      <td>7200</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@stillgray Really? 🤔</td>\n",
       "      <td>11125</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_CryMiaRiver @krassenstein @ZubyMusic I repea...</td>\n",
       "      <td>7635</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@krassenstein @ZubyMusic Please correct if wro...</td>\n",
       "      <td>2240</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  favorite_count   \n",
       "0                 @ispace_inc Stream on Twitter too!            3014  \\\n",
       "1  @zerohedge So bizarre that people and companie...            7200   \n",
       "2                               @stillgray Really? 🤔           11125   \n",
       "3  @_CryMiaRiver @krassenstein @ZubyMusic I repea...            7635   \n",
       "4  @krassenstein @ZubyMusic Please correct if wro...            2240   \n",
       "\n",
       "  date_creation  retweet_count  \n",
       "0    2023-04-25            285  \n",
       "1    2023-04-25            636  \n",
       "2    2023-04-25            977  \n",
       "3    2023-04-25           1244  \n",
       "4    2023-04-25            108  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 ms, sys: 0 ns, total: 22.3 ms\n",
      "Wall time: 21.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>date_creation</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stream twitter</td>\n",
       "      <td>3014</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bizarre people companies use money management ...</td>\n",
       "      <td>7200</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really</td>\n",
       "      <td>11125</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>krassenstein zubymusic repeat statement parent...</td>\n",
       "      <td>7635</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zubymusic please correct wrong communitynotes</td>\n",
       "      <td>2240</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>nice elonmusk something dumb said definitely</td>\n",
       "      <td>10341</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>spacex gravity gravity time escape</td>\n",
       "      <td>5793</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>maybe x</td>\n",
       "      <td>61164</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>6187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>spacex tesla yay</td>\n",
       "      <td>5042</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>davidsacks theallinpod wow</td>\n",
       "      <td>1741</td>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  favorite_count   \n",
       "0                                        stream twitter            3014  \\\n",
       "1     bizarre people companies use money management ...            7200   \n",
       "2                                                really           11125   \n",
       "3     krassenstein zubymusic repeat statement parent...            7635   \n",
       "4         zubymusic please correct wrong communitynotes            2240   \n",
       "...                                                 ...             ...   \n",
       "1171       nice elonmusk something dumb said definitely           10341   \n",
       "1172                 spacex gravity gravity time escape            5793   \n",
       "1173                                            maybe x           61164   \n",
       "1174                                   spacex tesla yay            5042   \n",
       "1175                         davidsacks theallinpod wow            1741   \n",
       "\n",
       "     date_creation  retweet_count  \n",
       "0       2023-04-25            285  \n",
       "1       2023-04-25            636  \n",
       "2       2023-04-25            977  \n",
       "3       2023-04-25           1244  \n",
       "4       2023-04-25            108  \n",
       "...            ...            ...  \n",
       "1171    2023-04-25            484  \n",
       "1172    2023-04-24            375  \n",
       "1173    2023-04-24           6187  \n",
       "1174    2023-04-24            237  \n",
       "1175    2023-04-24            109  \n",
       "\n",
       "[1176 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 940\n",
      "TEST size: 236\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 750 µs, sys: 0 ns, total: 750 µs\n",
      "Wall time: 761 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 09:43:20,101 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.025>', 'datetime': '2023-04-26T09:43:20.101098', 'gensim': '4.3.1', 'python': '3.10.4 (main, Apr  3 2023, 22:35:52) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-1105-azure-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(vector_size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 09:43:37,404 : INFO : collecting all words and their counts\n",
      "2023-04-26 09:43:37,408 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-26 09:43:37,411 : INFO : collected 224 word types from a corpus of 5104 raw words and 940 sentences\n",
      "2023-04-26 09:43:37,412 : INFO : Creating a fresh vocabulary\n",
      "2023-04-26 09:43:37,414 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 224 unique words (100.00% of original 224, drops 0)', 'datetime': '2023-04-26T09:43:37.414818', 'gensim': '4.3.1', 'python': '3.10.4 (main, Apr  3 2023, 22:35:52) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-1105-azure-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2023-04-26 09:43:37,416 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 5104 word corpus (100.00% of original 5104, drops 0)', 'datetime': '2023-04-26T09:43:37.416043', 'gensim': '4.3.1', 'python': '3.10.4 (main, Apr  3 2023, 22:35:52) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-1105-azure-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2023-04-26 09:43:37,419 : INFO : deleting the raw counts dictionary of 224 items\n",
      "2023-04-26 09:43:37,420 : INFO : sample=0.001 downsamples 224 most-common words\n",
      "2023-04-26 09:43:37,421 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3526.172382918021 word corpus (69.1%% of prior 5104)', 'datetime': '2023-04-26T09:43:37.421392', 'gensim': '4.3.1', 'python': '3.10.4 (main, Apr  3 2023, 22:35:52) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-1105-azure-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2023-04-26 09:43:37,503 : INFO : estimated required memory for 224 words and 300 dimensions: 649600 bytes\n",
      "2023-04-26 09:43:37,509 : INFO : resetting layer weights\n",
      "2023-04-26 09:43:37,551 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-26T09:43:37.551259', 'gensim': '4.3.1', 'python': '3.10.4 (main, Apr  3 2023, 22:35:52) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-1105-azure-x86_64-with-glibc2.31', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 224\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.key_to_index.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 09:45:43,262 : INFO : Word2Vec lifecycle event {'msg': 'training model with 8 workers on 224 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-04-26T09:45:43.262591', 'gensim': '4.3.1', 'python': '3.10.4 (main, Apr  3 2023, 22:35:52) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-1105-azure-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2023-04-26 09:45:43,370 : INFO : EPOCH 0: training on 5104 raw words (3440 effective words) took 0.1s, 56048 effective words/s\n",
      "2023-04-26 09:45:43,385 : INFO : EPOCH 1: training on 5104 raw words (3586 effective words) took 0.0s, 365729 effective words/s\n",
      "2023-04-26 09:45:43,402 : INFO : EPOCH 2: training on 5104 raw words (3515 effective words) took 0.0s, 439383 effective words/s\n",
      "2023-04-26 09:45:43,434 : INFO : EPOCH 3: training on 5104 raw words (3551 effective words) took 0.0s, 265748 effective words/s\n",
      "2023-04-26 09:45:43,516 : INFO : EPOCH 4: training on 5104 raw words (3560 effective words) took 0.0s, 335635 effective words/s\n",
      "2023-04-26 09:45:43,567 : INFO : EPOCH 5: training on 5104 raw words (3500 effective words) took 0.0s, 499575 effective words/s\n",
      "2023-04-26 09:45:43,589 : INFO : EPOCH 6: training on 5104 raw words (3490 effective words) took 0.0s, 231653 effective words/s\n",
      "2023-04-26 09:45:43,616 : INFO : EPOCH 7: training on 5104 raw words (3540 effective words) took 0.0s, 538924 effective words/s\n",
      "2023-04-26 09:45:43,627 : INFO : EPOCH 8: training on 5104 raw words (3520 effective words) took 0.0s, 504193 effective words/s\n",
      "2023-04-26 09:45:43,639 : INFO : EPOCH 9: training on 5104 raw words (3488 effective words) took 0.0s, 398895 effective words/s\n",
      "2023-04-26 09:45:43,651 : INFO : EPOCH 10: training on 5104 raw words (3537 effective words) took 0.0s, 435443 effective words/s\n",
      "2023-04-26 09:45:43,663 : INFO : EPOCH 11: training on 5104 raw words (3492 effective words) took 0.0s, 492126 effective words/s\n",
      "2023-04-26 09:45:43,675 : INFO : EPOCH 12: training on 5104 raw words (3535 effective words) took 0.0s, 500011 effective words/s\n",
      "2023-04-26 09:45:43,687 : INFO : EPOCH 13: training on 5104 raw words (3534 effective words) took 0.0s, 390292 effective words/s\n",
      "2023-04-26 09:45:43,705 : INFO : EPOCH 14: training on 5104 raw words (3530 effective words) took 0.0s, 440685 effective words/s\n",
      "2023-04-26 09:45:43,716 : INFO : EPOCH 15: training on 5104 raw words (3533 effective words) took 0.0s, 514681 effective words/s\n",
      "2023-04-26 09:45:43,730 : INFO : EPOCH 16: training on 5104 raw words (3539 effective words) took 0.0s, 463836 effective words/s\n",
      "2023-04-26 09:45:43,740 : INFO : EPOCH 17: training on 5104 raw words (3549 effective words) took 0.0s, 584723 effective words/s\n",
      "2023-04-26 09:45:43,751 : INFO : EPOCH 18: training on 5104 raw words (3475 effective words) took 0.0s, 498397 effective words/s\n",
      "2023-04-26 09:45:43,762 : INFO : EPOCH 19: training on 5104 raw words (3508 effective words) took 0.0s, 492527 effective words/s\n",
      "2023-04-26 09:45:43,771 : INFO : EPOCH 20: training on 5104 raw words (3520 effective words) took 0.0s, 539030 effective words/s\n",
      "2023-04-26 09:45:43,782 : INFO : EPOCH 21: training on 5104 raw words (3510 effective words) took 0.0s, 620949 effective words/s\n",
      "2023-04-26 09:45:43,793 : INFO : EPOCH 22: training on 5104 raw words (3548 effective words) took 0.0s, 486217 effective words/s\n",
      "2023-04-26 09:45:43,810 : INFO : EPOCH 23: training on 5104 raw words (3497 effective words) took 0.0s, 438916 effective words/s\n",
      "2023-04-26 09:45:43,820 : INFO : EPOCH 24: training on 5104 raw words (3562 effective words) took 0.0s, 552544 effective words/s\n",
      "2023-04-26 09:45:43,831 : INFO : EPOCH 25: training on 5104 raw words (3518 effective words) took 0.0s, 505791 effective words/s\n",
      "2023-04-26 09:45:43,841 : INFO : EPOCH 26: training on 5104 raw words (3466 effective words) took 0.0s, 557886 effective words/s\n",
      "2023-04-26 09:45:43,851 : INFO : EPOCH 27: training on 5104 raw words (3522 effective words) took 0.0s, 536968 effective words/s\n",
      "2023-04-26 09:45:43,861 : INFO : EPOCH 28: training on 5104 raw words (3583 effective words) took 0.0s, 532420 effective words/s\n",
      "2023-04-26 09:45:43,871 : INFO : EPOCH 29: training on 5104 raw words (3551 effective words) took 0.0s, 545515 effective words/s\n",
      "2023-04-26 09:45:43,881 : INFO : EPOCH 30: training on 5104 raw words (3543 effective words) took 0.0s, 532858 effective words/s\n",
      "2023-04-26 09:45:43,892 : INFO : EPOCH 31: training on 5104 raw words (3568 effective words) took 0.0s, 546850 effective words/s\n",
      "2023-04-26 09:45:43,892 : INFO : Word2Vec lifecycle event {'msg': 'training on 163328 raw words (112810 effective words) took 0.6s, 179443 effective words/s', 'datetime': '2023-04-26T09:45:43.892932', 'gensim': '4.3.1', 'python': '3.10.4 (main, Apr  3 2023, 22:35:52) [GCC 9.4.0]', 'platform': 'Linux-5.4.0-1105-azure-x86_64-with-glibc2.31', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 365 ms, sys: 56.8 ms, total: 422 ms\n",
      "Wall time: 631 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(112810, 163328)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
